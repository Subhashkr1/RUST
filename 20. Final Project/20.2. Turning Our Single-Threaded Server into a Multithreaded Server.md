# Implementing a Multithreaded Web Server in Rust

## Introduction
This section of *The Rust Programming Language* (The Rust Book) covers how to enhance a basic web server by making it multithreaded. The goal is to handle multiple requests concurrently using Rust's threading model and a thread pool.

## Why Multithreading?
A single-threaded web server processes one request at a time. This means:
- If one request takes a long time, all others are blocked.
- The server cannot take advantage of multiple CPU cores.

By using multithreading, we can improve performance and responsiveness by handling multiple requests in parallel.

## Steps to Implement a Multithreaded Web Server

### 1. Spawning a New Thread for Each Request
The naive approach is to spawn a new thread for every incoming request using `std::thread::spawn`. Example:

```rust
use std::thread;
use std::net::{TcpListener, TcpStream};

fn handle_connection(stream: TcpStream) {
    // Process request...
}

fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    
    for stream in listener.incoming() {
        let stream = stream.unwrap();
        
        thread::spawn(|| {
            handle_connection(stream);
        });
    }
}
```

**Issues:**
- Creating too many threads can overwhelm system resources.
- Threads have memory overhead and context-switching costs.

### 2. Using a Thread Pool
A better approach is to create a fixed number of threads and assign requests to them. This avoids excessive thread creation and optimizes resource usage.

#### **Building a Simple Thread Pool**

1. **Define a `ThreadPool` struct:**

```rust
struct ThreadPool {
    workers: Vec<Worker>,
    sender: mpsc::Sender<Job>,
}
```
- `workers`: A vector of worker threads.
- `sender`: A channel to send jobs to workers.

2. **Create Worker Struct**
Each worker has:
- An `id`.
- A thread handling incoming jobs.

```rust
struct Worker {
    id: usize,
    thread: Option<thread::JoinHandle<()>>,
}
```

3. **Implementing the `ThreadPool::new` Method**
```rust
impl ThreadPool {
    fn new(size: usize) -> ThreadPool {
        let (sender, receiver) = mpsc::channel();
        let receiver = Arc::new(Mutex::new(receiver));
        
        let mut workers = Vec::with_capacity(size);
        
        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }
        
        ThreadPool { workers, sender }
    }
}
```

4. **Implementing Worker Threads**
Workers continuously pick jobs from the queue and execute them.

```rust
impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || {
            while let Ok(job) = receiver.lock().unwrap().recv() {
                job();
            }
        });
        
        Worker { id, thread: Some(thread) }
    }
}
```

5. **Implementing the `execute` Method**
The `execute` method allows the server to send jobs to the thread pool.

```rust
impl ThreadPool {
    fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);
        self.sender.send(job).unwrap();
    }
}
```

### 3. Integrating Thread Pool into the Server
Modify `main` to use the thread pool:

```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4); // Create a pool of 4 threads
    
    for stream in listener.incoming().take(2) { // Process 2 requests then shutdown
        let stream = stream.unwrap();
        
        pool.execute(|| {
            handle_connection(stream);
        });
    }
}
```

### 4. Graceful Shutdown
To allow a clean shutdown, modify workers to listen for a shutdown signal.

```rust
struct Worker {
    id: usize,
    thread: Option<thread::JoinHandle<()>>,
}

impl Drop for ThreadPool {
    fn drop(&mut self) {
        println!("Shutting down workers.");
        
        for worker in &mut self.workers {
            if let Some(thread) = worker.thread.take() {
                thread.join().unwrap();
            }
        }
    }
}
```

## Summary
- **Naive approach:** Spawning a thread per request (inefficient).
- **Optimized approach:** Using a thread pool to manage worker threads efficiently.
- **Graceful shutdown:** Ensuring workers terminate cleanly when the server stops.

This implementation makes our web server **efficient**, **scalable**, and **stable**.
